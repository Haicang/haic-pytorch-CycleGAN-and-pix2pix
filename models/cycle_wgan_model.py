from .cycle_gan_model import *

class CycleWGANModel(CycleGANModel):
    """
    WGAN version of CycleGAN
    """
    def __init__(self, opt):
        return super().__init__(opt)

    def backward_D_basic(self, netD, real, fake):
        """Calculate WGAN loss for the discriminator

        Parameters:
            netD (network)      -- the discriminator D
            real (tensor array) -- real images
            fake (tensor array) -- images generated by a generator

        Return the discriminator loss.
        We also call loss_D.backward() to calculate the gradients.
        """
        # Real
        pred_real = netD(real)
        loss_D_real = self.criterionGAN(pred_real, True)
        # Fake
        pred_fake = netD(fake.detach())
        loss_D_fake = self.criterionGAN(pred_fake, False)
        # Combined loss and calculate gradients
        gp, g = networks.cal_gradient_penalty(netD, real, fake.detach(), self.device)
        print(gp, g)
        loss_D = (loss_D_real + loss_D_fake) * 0.5 + gp
        print(loss_D)
        loss_D.backward(retain_graph=True)
        return loss_D

    def optimize_D(self):
        """
        Only optimize the Discriminator
        """
        # forward
        self.forward()      # compute fake images and reconstruction images.
        # D_A and D_B
        self.set_requires_grad([self.netD_A, self.netD_B], True)
        # self.set_requires_grad([self.netG_A, self.netG_B], False)
        self.optimizer_D.zero_grad()   # set D_A and D_B's gradients to zero
        self.backward_D_A()      # calculate gradients for D_A
        self.backward_D_B()      # calculate graidents for D_B
        self.optimizer_D.step()  # update D_A and D_B's weights

    def optimize_parameters(self, updateG=False):
        """
        Calculate losses, gradients, and update network weights; 
        called in every training iteration

        In wgan, we should update Discriminator n_critic times 
        before updating Generator
        """
        self.optimize_D()
        if updateG:
            # G_A and G_B
            self.set_requires_grad([self.netD_A, self.netD_B], False)  # Ds require no gradients when optimizing Gs
            # self.set_requires_grad([self.netG_A, self.netG_B], True)
            self.optimizer_G.zero_grad()  # set G_A and G_B's gradients to zero
            self.backward_G()             # calculate gradients for G_A and G_B
            self.optimizer_G.step()       # update G_A and G_B's weights
